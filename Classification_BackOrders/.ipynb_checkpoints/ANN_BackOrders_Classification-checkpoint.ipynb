{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "    Identify products at risk of backorder before the event occurs so the business has time to react. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing\n",
    "#### Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gaurang/Gaurang/Batch47/AI/20181215_Batch47_CSE7321c_Lab02_ANN/20181215_Batch47_CSE7321c_Lab01'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For setting working directory, if required\n",
    "#os.chdir('path to file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"BackOrders.csv\",header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the number row and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61589, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sku', 'national_inv', 'lead_time', 'in_transit_qty',\n",
       "       'forecast_3_month', 'forecast_6_month', 'forecast_9_month',\n",
       "       'sales_1_month', 'sales_3_month', 'sales_6_month', 'sales_9_month',\n",
       "       'min_bank', 'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
       "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
       "       'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=61589, step=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the top rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1888279</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1870557</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1475481</td>\n",
       "      <td>258</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>184</td>\n",
       "      <td>46</td>\n",
       "      <td>132</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0  1888279           117        NaN               0                 0   \n",
       "1  1870557             7        2.0               0                 0   \n",
       "2  1475481           258       15.0              10                10   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0                 0                 0              0              0   \n",
       "1                 0                 0              0              0   \n",
       "2                77               184             46            132   \n",
       "\n",
       "   sales_6_month        ...         pieces_past_due  perf_6_month_avg  \\\n",
       "0             15        ...                       0            -99.00   \n",
       "1              0        ...                       0              0.50   \n",
       "2            256        ...                       0              0.54   \n",
       "\n",
       "  perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint  ppap_risk  \\\n",
       "0            -99.00             0         No             No        Yes   \n",
       "1              0.28             0        Yes             No         No   \n",
       "2              0.70             0         No             No         No   \n",
       "\n",
       "  stop_auto_buy rev_stop went_on_backorder  \n",
       "0           Yes       No                No  \n",
       "1           Yes       No                No  \n",
       "2           Yes       No                No  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows a quick statistic summary of your data using describe.\n",
    "\n",
    "For object data (e.g. strings or timestamps), the result’s index will include count, unique, top, and freq. \n",
    "\n",
    "The top is the most common value.\n",
    "\n",
    "The freq is the most common value’s frequency.\n",
    "\n",
    "Timestamps also include the first and last items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>58186.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48145</td>\n",
       "      <td>61577</td>\n",
       "      <td>53792</td>\n",
       "      <td>59303</td>\n",
       "      <td>61569</td>\n",
       "      <td>50296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.037188e+06</td>\n",
       "      <td>287.721882</td>\n",
       "      <td>7.559619</td>\n",
       "      <td>30.192843</td>\n",
       "      <td>1.692728e+02</td>\n",
       "      <td>3.150413e+02</td>\n",
       "      <td>4.535760e+02</td>\n",
       "      <td>44.742957</td>\n",
       "      <td>150.732631</td>\n",
       "      <td>2.835465e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.605400</td>\n",
       "      <td>-6.264182</td>\n",
       "      <td>-5.863664</td>\n",
       "      <td>1.205361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.564178e+05</td>\n",
       "      <td>4233.906931</td>\n",
       "      <td>6.498952</td>\n",
       "      <td>792.869253</td>\n",
       "      <td>5.286742e+03</td>\n",
       "      <td>9.774362e+03</td>\n",
       "      <td>1.420201e+04</td>\n",
       "      <td>1373.805831</td>\n",
       "      <td>5224.959649</td>\n",
       "      <td>8.872270e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>42.309229</td>\n",
       "      <td>25.537906</td>\n",
       "      <td>24.844514</td>\n",
       "      <td>29.981155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.068628e+06</td>\n",
       "      <td>-2999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.498574e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.898033e+06</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.314826e+06</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.284895e+06</td>\n",
       "      <td>673445.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>170976.000000</td>\n",
       "      <td>1.126656e+06</td>\n",
       "      <td>2.094336e+06</td>\n",
       "      <td>3.062016e+06</td>\n",
       "      <td>295197.000000</td>\n",
       "      <td>934593.000000</td>\n",
       "      <td>1.799099e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7392.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sku   national_inv     lead_time  in_transit_qty  \\\n",
       "count   6.158900e+04   61589.000000  58186.000000    61589.000000   \n",
       "unique           NaN            NaN           NaN             NaN   \n",
       "top              NaN            NaN           NaN             NaN   \n",
       "freq             NaN            NaN           NaN             NaN   \n",
       "mean    2.037188e+06     287.721882      7.559619       30.192843   \n",
       "std     6.564178e+05    4233.906931      6.498952      792.869253   \n",
       "min     1.068628e+06   -2999.000000      0.000000        0.000000   \n",
       "25%     1.498574e+06       3.000000      4.000000        0.000000   \n",
       "50%     1.898033e+06      10.000000      8.000000        0.000000   \n",
       "75%     2.314826e+06      57.000000      8.000000        0.000000   \n",
       "max     3.284895e+06  673445.000000     52.000000   170976.000000   \n",
       "\n",
       "        forecast_3_month  forecast_6_month  forecast_9_month  sales_1_month  \\\n",
       "count       6.158900e+04      6.158900e+04      6.158900e+04   61589.000000   \n",
       "unique               NaN               NaN               NaN            NaN   \n",
       "top                  NaN               NaN               NaN            NaN   \n",
       "freq                 NaN               NaN               NaN            NaN   \n",
       "mean        1.692728e+02      3.150413e+02      4.535760e+02      44.742957   \n",
       "std         5.286742e+03      9.774362e+03      1.420201e+04    1373.805831   \n",
       "min         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "25%         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "50%         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "75%         1.200000e+01      2.500000e+01      3.600000e+01       6.000000   \n",
       "max         1.126656e+06      2.094336e+06      3.062016e+06  295197.000000   \n",
       "\n",
       "        sales_3_month  sales_6_month        ...         pieces_past_due  \\\n",
       "count    61589.000000   6.158900e+04        ...            61589.000000   \n",
       "unique            NaN            NaN        ...                     NaN   \n",
       "top               NaN            NaN        ...                     NaN   \n",
       "freq              NaN            NaN        ...                     NaN   \n",
       "mean       150.732631   2.835465e+02        ...                1.605400   \n",
       "std       5224.959649   8.872270e+03        ...               42.309229   \n",
       "min          0.000000   0.000000e+00        ...                0.000000   \n",
       "25%          0.000000   0.000000e+00        ...                0.000000   \n",
       "50%          2.000000   4.000000e+00        ...                0.000000   \n",
       "75%         17.000000   3.400000e+01        ...                0.000000   \n",
       "max     934593.000000   1.799099e+06        ...             7392.000000   \n",
       "\n",
       "        perf_6_month_avg perf_12_month_avg  local_bo_qty  deck_risk  \\\n",
       "count       61589.000000      61589.000000  61589.000000      61589   \n",
       "unique               NaN               NaN           NaN          2   \n",
       "top                  NaN               NaN           NaN         No   \n",
       "freq                 NaN               NaN           NaN      48145   \n",
       "mean           -6.264182         -5.863664      1.205361        NaN   \n",
       "std            25.537906         24.844514     29.981155        NaN   \n",
       "min           -99.000000        -99.000000      0.000000        NaN   \n",
       "25%             0.620000          0.640000      0.000000        NaN   \n",
       "50%             0.820000          0.800000      0.000000        NaN   \n",
       "75%             0.960000          0.950000      0.000000        NaN   \n",
       "max             1.000000          1.000000   2999.000000        NaN   \n",
       "\n",
       "        oe_constraint  ppap_risk stop_auto_buy rev_stop went_on_backorder  \n",
       "count           61589      61589         61589    61589             61589  \n",
       "unique              2          2             2        2                 2  \n",
       "top                No         No           Yes       No                No  \n",
       "freq            61577      53792         59303    61569             50296  \n",
       "mean              NaN        NaN           NaN      NaN               NaN  \n",
       "std               NaN        NaN           NaN      NaN               NaN  \n",
       "min               NaN        NaN           NaN      NaN               NaN  \n",
       "25%               NaN        NaN           NaN      NaN               NaN  \n",
       "50%               NaN        NaN           NaN      NaN               NaN  \n",
       "75%               NaN        NaN           NaN      NaN               NaN  \n",
       "max               NaN        NaN           NaN      NaN               NaN  \n",
       "\n",
       "[11 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display data type of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                    int64\n",
       "national_inv           int64\n",
       "lead_time            float64\n",
       "in_transit_qty         int64\n",
       "forecast_3_month       int64\n",
       "forecast_6_month       int64\n",
       "forecast_9_month       int64\n",
       "sales_1_month          int64\n",
       "sales_3_month          int64\n",
       "sales_6_month          int64\n",
       "sales_9_month          int64\n",
       "min_bank               int64\n",
       "potential_issue       object\n",
       "pieces_past_due        int64\n",
       "perf_6_month_avg     float64\n",
       "perf_12_month_avg    float64\n",
       "local_bo_qty           int64\n",
       "deck_risk             object\n",
       "oe_constraint         object\n",
       "ppap_risk             object\n",
       "stop_auto_buy         object\n",
       "rev_stop              object\n",
       "went_on_backorder     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "sku is Categorical but is interpreted as int64 \n",
    "potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, and went_on_backorder are also \n",
    "categorical but is interpreted as object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all the attributes to appropriate type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type conversion\n",
    "\n",
    "    Using astype('category') to convert potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, and went_on_backorder attributes to categorical attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['sku', 'potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder']:\n",
    "    data[col] = data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display data type of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                  category\n",
       "national_inv            int64\n",
       "lead_time             float64\n",
       "in_transit_qty          int64\n",
       "forecast_3_month        int64\n",
       "forecast_6_month        int64\n",
       "forecast_9_month        int64\n",
       "sales_1_month           int64\n",
       "sales_3_month           int64\n",
       "sales_6_month           int64\n",
       "sales_9_month           int64\n",
       "min_bank                int64\n",
       "potential_issue      category\n",
       "pieces_past_due         int64\n",
       "perf_6_month_avg      float64\n",
       "perf_12_month_avg     float64\n",
       "local_bo_qty            int64\n",
       "deck_risk            category\n",
       "oe_constraint        category\n",
       "ppap_risk            category\n",
       "stop_auto_buy        category\n",
       "rev_stop             category\n",
       "went_on_backorder    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete sku attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61589"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(np.unique(data.sku))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('sku', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data\n",
    "\n",
    "Missing value analysis and dropping the records with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv            0\n",
       "lead_time            3403\n",
       "in_transit_qty          0\n",
       "forecast_3_month        0\n",
       "forecast_6_month        0\n",
       "forecast_9_month        0\n",
       "sales_1_month           0\n",
       "sales_3_month           0\n",
       "sales_6_month           0\n",
       "sales_9_month           0\n",
       "min_bank                0\n",
       "potential_issue         0\n",
       "pieces_past_due         0\n",
       "perf_6_month_avg        0\n",
       "perf_12_month_avg       0\n",
       "local_bo_qty            0\n",
       "deck_risk               0\n",
       "oe_constraint           0\n",
       "ppap_risk               0\n",
       "stop_auto_buy           0\n",
       "rev_stop                0\n",
       "went_on_backorder       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the number of records before and after missing value records removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61589, 22)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the number of missing values is about 5%. For initial analysis we ignore all these records\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "national_inv         0\n",
      "lead_time            0\n",
      "in_transit_qty       0\n",
      "forecast_3_month     0\n",
      "forecast_6_month     0\n",
      "forecast_9_month     0\n",
      "sales_1_month        0\n",
      "sales_3_month        0\n",
      "sales_6_month        0\n",
      "sales_9_month        0\n",
      "min_bank             0\n",
      "potential_issue      0\n",
      "pieces_past_due      0\n",
      "perf_6_month_avg     0\n",
      "perf_12_month_avg    0\n",
      "local_bo_qty         0\n",
      "deck_risk            0\n",
      "oe_constraint        0\n",
      "ppap_risk            0\n",
      "stop_auto_buy        0\n",
      "rev_stop             0\n",
      "went_on_backorder    0\n",
      "dtype: int64\n",
      "----------------------------------\n",
      "(58186, 22)\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "print(\"----------------------------------\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Categorical to Numeric\n",
    "\n",
    "For some of the models all the independent attribute should be of type numeric and ANN model is one among them.\n",
    "But this data set has some categorial attributes.\n",
    "\n",
    "'pandas.get_dummies' To convert convert categorical variable into dummy/indicator variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
      "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
      "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
      "       'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
      "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
      "       'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating dummy variables.\n",
    "\n",
    "If we have k levels in a category, then we create k-1 dummy variables as the last one would be redundant. So we use the parameter drop_first in pd.get_dummies function that drops the first level in each of the category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_Attributes = data.select_dtypes(include=['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(columns=categorical_Attributes, data=data, prefix=categorical_Attributes, prefix_sep=\"_\",drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
      "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
      "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
      "       'pieces_past_due', 'perf_6_month_avg', 'perf_12_month_avg',\n",
      "       'local_bo_qty', 'potential_issue_Yes', 'deck_risk_Yes',\n",
      "       'oe_constraint_Yes', 'ppap_risk_Yes', 'stop_auto_buy_Yes',\n",
      "       'rev_stop_Yes', 'went_on_backorder_Yes'],\n",
      "      dtype='object') (58186, 22)\n"
     ]
    }
   ],
   "source": [
    "print (data.columns, data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target attribute distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    47217\n",
       "1    10969\n",
       "Name: went_on_backorder_Yes, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(data['went_on_backorder_Yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split\n",
    "\n",
    "Using sklearn.model_selection.train_test_split\n",
    "\n",
    "    Split arrays or matrices into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing train test split on the data\n",
    "X, y = data.loc[:,data.columns!='went_on_backorder_Yes'].values, data.loc[:,'went_on_backorder_Yes'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify = data['went_on_backorder_Yes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    33052\n",
      "1     7678\n",
      "dtype: int64\n",
      "0    14165\n",
      "1     3291\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To get the distribution in the target in train and test\n",
    "print(pd.value_counts(y_train))\n",
    "print(pd.value_counts(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building a logistic regression model using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on train data\n",
    "train_pred = classifier.predict(X_train)\n",
    "# Predictions on test data\n",
    "test_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Train Data: \n",
      " [[32880   172]\n",
      " [ 7094   584]]\n",
      "Confusion Matrix - Test Data: \n",
      " [[14101    64]\n",
      " [ 3029   262]]\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "print(\"Confusion Matrix - Train Data: \\n\", confusion_matrix_train)\n",
    "# Test data\n",
    "confusion_matrix_test= confusion_matrix(y_test, test_pred)\n",
    "print(\"Confusion Matrix - Test Data: \\n\", confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Specificity:  0.9947960789059663\n",
      "Train Recall:  0.07606147434227663\n",
      "Train Precision:  0.7724867724867724\n",
      "Train Accuracy:  0.8216056960471397\n"
     ]
    }
   ],
   "source": [
    "# Metrics on train data for logistic regression model\n",
    "#Accuracy\n",
    "accuracy_Train_logReg = (confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Train_logReg = confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Train_logReg = confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#precision\n",
    "precision_Train_logReg = confusion_matrix_train[1,1]/(confusion_matrix_train[0,1]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train Specificity: \",specificity_Train_logReg)\n",
    "print(\"Train Recall: \",recall_Train_logReg)\n",
    "print(\"Train Precision: \",precision_Train_logReg)\n",
    "print(\"Train Accuracy: \",accuracy_Train_logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Specificity:  0.9954818213907518\n",
      "Test Recall:  0.07961106046794288\n",
      "Test Precision:  0.803680981595092\n",
      "Test Accuracy:  0.8228116406966086\n"
     ]
    }
   ],
   "source": [
    "# Metrics on test data\n",
    "#Accuracy\n",
    "accuracy_Test_logReg = (confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Test_logReg = confusion_matrix_test[0,0]/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Test_logReg = confusion_matrix_test[1,1]/(confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#precision\n",
    "precision_Test_logReg = confusion_matrix_test[1,1]/(confusion_matrix_test[0,1]+confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test Specificity: \",specificity_Test_logReg)\n",
    "print(\"Test Recall: \",recall_Test_logReg)\n",
    "print(\"Test Precision: \",precision_Test_logReg)\n",
    "print(\"Test Accuracy: \",accuracy_Test_logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40730,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fc_dense_layers_keras.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. The core data structure of Keras is a model, a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. \n",
    "\n",
    "* The keras sequential api enables us to build common yet complex neural network architectures flexibly\n",
    "\n",
    "* Objects of the Keras sequential class, can have multiple neural network layers stacked on top of one another\n",
    "\n",
    "![](img/keras_sequential_api.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=64, input_dim=21, activation='relu', ))\n",
    "model.add(Dense(units=1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 64)                1408      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. Compilation\n",
    "Before training a model, you need to configure the learning process, which is done via the compile method. receives three arguments\n",
    "\n",
    "* optimizer - An optimizer. An optimizer is an algorithm that uses this feedback signal, to actually update the weights so that the output from the network gets closer to the ground truth.\n",
    "* loss - A loss function. This is the objective that the model will try to minimize.\n",
    "* metrics - A list of error metrics. This is for users reference and does not add value to the weights calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C. Training\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the  fit function\n",
    "\n",
    "* epoch = one forward pass and one backward pass of all the training examples\n",
    "* batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40730/40730 [==============================] - 1s 16us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 2/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 3/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 4/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 5/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 6/100\n",
      "40730/40730 [==============================] - 1s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 7/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 8/100\n",
      "40730/40730 [==============================] - 1s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 9/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 10/100\n",
      "40730/40730 [==============================] - 1s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 11/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 12/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 13/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 14/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 15/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 16/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 17/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 18/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 19/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 20/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 21/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 22/100\n",
      "40730/40730 [==============================] - 1s 17us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 23/100\n",
      "40730/40730 [==============================] - 1s 16us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 24/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 25/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 26/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 27/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 28/100\n",
      "40730/40730 [==============================] - 1s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 29/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 30/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 31/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 32/100\n",
      "40730/40730 [==============================] - 1s 14us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 33/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 34/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 35/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 36/100\n",
      "40730/40730 [==============================] - 1s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 37/100\n",
      "40730/40730 [==============================] - 1s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 38/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 39/100\n",
      "40730/40730 [==============================] - 1s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 40/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 41/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 42/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 43/100\n",
      "40730/40730 [==============================] - 1s 15us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 44/100\n",
      "40730/40730 [==============================] - 1s 17us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 45/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 46/100\n",
      "40730/40730 [==============================] - 1s 14us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 47/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 48/100\n",
      "40730/40730 [==============================] - 1s 15us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 49/100\n",
      "40730/40730 [==============================] - 1s 14us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 50/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 51/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 52/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 53/100\n",
      "40730/40730 [==============================] - 1s 14us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 54/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 55/100\n",
      "40730/40730 [==============================] - 1s 15us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 56/100\n",
      "40730/40730 [==============================] - 1s 17us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 57/100\n",
      "40730/40730 [==============================] - 1s 15us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 58/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 59/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 60/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 61/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 62/100\n",
      "40730/40730 [==============================] - 1s 18us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 63/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 64/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 65/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 66/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 67/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 68/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 69/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 70/100\n",
      "40730/40730 [==============================] - 1s 16us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 71/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 72/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 73/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 74/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 75/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 76/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 77/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 78/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 79/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 80/100\n",
      "40730/40730 [==============================] - 1s 16us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 81/100\n",
      "40730/40730 [==============================] - 1s 14us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 82/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 83/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 84/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 85/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 86/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 87/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 88/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 89/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 90/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 91/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 92/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 93/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 94/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 95/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 96/100\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 97/100\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 98/100\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 99/100\n",
      "40730/40730 [==============================] - 0s 10us/step - loss: 12.9371 - acc: 0.1885\n",
      "Epoch 100/100\n",
      "40730/40730 [==============================] - 1s 14us/step - loss: 12.9371 - acc: 0.1885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72602dbb00>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE : Don't run the following line of code as we do not yet have X_train and y_train\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model = Sequential()\n",
    "\n",
    "perceptron_model.add(Dense(1, input_dim=21, activation='sigmoid', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40730/40730 [==============================] - 1s 16us/step - loss: 0.6942 - acc: 0.7877\n",
      "Epoch 2/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4015 - acc: 0.8445\n",
      "Epoch 3/30\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 0.4026 - acc: 0.8490\n",
      "Epoch 4/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4074 - acc: 0.8515\n",
      "Epoch 5/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4009 - acc: 0.8568\n",
      "Epoch 6/30\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 0.3987 - acc: 0.8597\n",
      "Epoch 7/30\n",
      "40730/40730 [==============================] - 1s 12us/step - loss: 0.4046 - acc: 0.8578\n",
      "Epoch 8/30\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 0.3929 - acc: 0.8638\n",
      "Epoch 9/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4222 - acc: 0.8592\n",
      "Epoch 10/30\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 0.3930 - acc: 0.8639\n",
      "Epoch 11/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.3976 - acc: 0.8630\n",
      "Epoch 12/30\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 0.4145 - acc: 0.8600\n",
      "Epoch 13/30\n",
      "40730/40730 [==============================] - 1s 12us/step - loss: 0.3932 - acc: 0.8646\n",
      "Epoch 14/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4107 - acc: 0.8636\n",
      "Epoch 15/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4126 - acc: 0.8636\n",
      "Epoch 16/30\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 0.4090 - acc: 0.8653\n",
      "Epoch 17/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4023 - acc: 0.8672\n",
      "Epoch 18/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4117 - acc: 0.8671\n",
      "Epoch 19/30\n",
      "40730/40730 [==============================] - 1s 15us/step - loss: 0.4214 - acc: 0.8644\n",
      "Epoch 20/30\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 0.4006 - acc: 0.8658\n",
      "Epoch 21/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4062 - acc: 0.8640\n",
      "Epoch 22/30\n",
      "40730/40730 [==============================] - 1s 14us/step - loss: 0.4086 - acc: 0.8663\n",
      "Epoch 23/30\n",
      "40730/40730 [==============================] - 1s 15us/step - loss: 0.3981 - acc: 0.8658\n",
      "Epoch 24/30\n",
      "40730/40730 [==============================] - 1s 13us/step - loss: 0.4013 - acc: 0.8653\n",
      "Epoch 25/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.3946 - acc: 0.8656\n",
      "Epoch 26/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4018 - acc: 0.8643\n",
      "Epoch 27/30\n",
      "40730/40730 [==============================] - 0s 11us/step - loss: 0.3948 - acc: 0.8661\n",
      "Epoch 28/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4029 - acc: 0.8658\n",
      "Epoch 29/30\n",
      "40730/40730 [==============================] - 0s 12us/step - loss: 0.4348 - acc: 0.8620\n",
      "Epoch 30/30\n",
      "40730/40730 [==============================] - 1s 15us/step - loss: 0.4100 - acc: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69c7863860>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model.fit(X_train, y_train, epochs=30, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31760  1292]\n",
      " [ 4009  3669]]\n",
      "[[13572   593]\n",
      " [ 1713  1578]]\n"
     ]
    }
   ],
   "source": [
    "test_pred=perceptron_model.predict_classes(X_test)\n",
    "train_pred=perceptron_model.predict_classes(X_train)\n",
    "\n",
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "\n",
    "print(confusion_matrix_train)\n",
    "print(confusion_matrix_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Test Accuracy, True Negative Rate and True Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TNR:  0.9609100810843519\n",
      "Train TPR:  0.4778588174003647\n",
      "Train Accuracy:  0.8698502332433096\n",
      "-----------------------\n",
      "Test TNR:  0.9581362513236852\n",
      "Test TPR:  0.479489516864175\n",
      "Test Accuracy:  0.8678964252978918\n"
     ]
    }
   ],
   "source": [
    "Accuracy_Train=(confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "TNR_Train= confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "TPR_Train= confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train TNR: \",TNR_Train)\n",
    "print(\"Train TPR: \",TPR_Train)\n",
    "print(\"Train Accuracy: \",Accuracy_Train)\n",
    "print(\"-----------------------\")\n",
    "\n",
    "Accuracy_Test=(confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "TNR_Test= confusion_matrix_test[0,0]/(confusion_matrix_test[0,0] +confusion_matrix_test[0,1])\n",
    "TPR_Test= confusion_matrix_test[1,1]/(confusion_matrix_test[1,0] +confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test TNR: \",TNR_Test)\n",
    "print(\"Test TPR: \",TPR_Test)\n",
    "print(\"Test Accuracy: \",Accuracy_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = Sequential()\n",
    "\n",
    "mlp_model.add(Dense(12, input_dim=21, activation='relu', kernel_initializer='normal'))\n",
    "mlp_model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32584 samples, validate on 8146 samples\n",
      "Epoch 1/30\n",
      "32584/32584 [==============================] - 1s 22us/step - loss: 0.4061 - acc: 0.8265 - val_loss: 0.3230 - val_acc: 0.8511\n",
      "Epoch 2/30\n",
      "32584/32584 [==============================] - 0s 14us/step - loss: 0.3025 - acc: 0.8751 - val_loss: 0.3026 - val_acc: 0.8833\n",
      "Epoch 3/30\n",
      "32584/32584 [==============================] - 0s 14us/step - loss: 0.2910 - acc: 0.8885 - val_loss: 0.2888 - val_acc: 0.8911\n",
      "Epoch 4/30\n",
      "32584/32584 [==============================] - 0s 14us/step - loss: 0.2803 - acc: 0.8944 - val_loss: 0.2845 - val_acc: 0.8973\n",
      "Epoch 5/30\n",
      "32584/32584 [==============================] - 0s 14us/step - loss: 0.2707 - acc: 0.8980 - val_loss: 0.2787 - val_acc: 0.9000\n",
      "Epoch 6/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2681 - acc: 0.8992 - val_loss: 0.2725 - val_acc: 0.9000\n",
      "Epoch 7/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2684 - acc: 0.8991 - val_loss: 0.2745 - val_acc: 0.8932\n",
      "Epoch 8/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2819 - acc: 0.8956 - val_loss: 0.2809 - val_acc: 0.8961\n",
      "Epoch 9/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2690 - acc: 0.8974 - val_loss: 0.2727 - val_acc: 0.8948\n",
      "Epoch 10/30\n",
      "32584/32584 [==============================] - 1s 18us/step - loss: 0.2564 - acc: 0.8999 - val_loss: 0.2671 - val_acc: 0.8975\n",
      "Epoch 11/30\n",
      "32584/32584 [==============================] - 1s 16us/step - loss: 0.2536 - acc: 0.9015 - val_loss: 0.2655 - val_acc: 0.8990\n",
      "Epoch 12/30\n",
      "32584/32584 [==============================] - 1s 20us/step - loss: 0.2580 - acc: 0.8997 - val_loss: 0.2628 - val_acc: 0.9008\n",
      "Epoch 13/30\n",
      "32584/32584 [==============================] - 1s 19us/step - loss: 0.2533 - acc: 0.9013 - val_loss: 0.2628 - val_acc: 0.9011\n",
      "Epoch 14/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2506 - acc: 0.9034 - val_loss: 0.2630 - val_acc: 0.9001\n",
      "Epoch 15/30\n",
      "32584/32584 [==============================] - 1s 21us/step - loss: 0.2497 - acc: 0.9009 - val_loss: 0.2613 - val_acc: 0.9006\n",
      "Epoch 16/30\n",
      "32584/32584 [==============================] - 1s 16us/step - loss: 0.2492 - acc: 0.9005 - val_loss: 0.2672 - val_acc: 0.8905\n",
      "Epoch 17/30\n",
      "32584/32584 [==============================] - 0s 14us/step - loss: 0.2476 - acc: 0.9019 - val_loss: 0.2606 - val_acc: 0.8961\n",
      "Epoch 18/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2481 - acc: 0.9033 - val_loss: 0.2621 - val_acc: 0.8973\n",
      "Epoch 19/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2456 - acc: 0.9038 - val_loss: 0.2540 - val_acc: 0.8992\n",
      "Epoch 20/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2447 - acc: 0.9046 - val_loss: 0.2568 - val_acc: 0.8998\n",
      "Epoch 21/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2447 - acc: 0.9037 - val_loss: 0.2572 - val_acc: 0.9028\n",
      "Epoch 22/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2438 - acc: 0.9036 - val_loss: 0.2655 - val_acc: 0.8968\n",
      "Epoch 23/30\n",
      "32584/32584 [==============================] - 0s 14us/step - loss: 0.2452 - acc: 0.9029 - val_loss: 0.2605 - val_acc: 0.9007\n",
      "Epoch 24/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2444 - acc: 0.9038 - val_loss: 0.2561 - val_acc: 0.9047\n",
      "Epoch 25/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2433 - acc: 0.9042 - val_loss: 0.2564 - val_acc: 0.9023\n",
      "Epoch 26/30\n",
      "32584/32584 [==============================] - 0s 14us/step - loss: 0.2456 - acc: 0.9048 - val_loss: 0.2615 - val_acc: 0.8961\n",
      "Epoch 27/30\n",
      "32584/32584 [==============================] - 1s 17us/step - loss: 0.2421 - acc: 0.9034 - val_loss: 0.2578 - val_acc: 0.9025\n",
      "Epoch 28/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2425 - acc: 0.9053 - val_loss: 0.2541 - val_acc: 0.9009\n",
      "Epoch 29/30\n",
      "32584/32584 [==============================] - 1s 16us/step - loss: 0.2525 - acc: 0.8992 - val_loss: 0.2552 - val_acc: 0.8958\n",
      "Epoch 30/30\n",
      "32584/32584 [==============================] - 0s 15us/step - loss: 0.2444 - acc: 0.9031 - val_loss: 0.2640 - val_acc: 0.9025\n"
     ]
    }
   ],
   "source": [
    "#model_history = ann_model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "model_history = mlp_model.fit(X_train, y_train, epochs=30, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = mlp_model.predict_classes(X_train)\n",
    "\n",
    "test_pred = mlp_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting evaluation metrics and evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31485  1567]\n",
      " [ 2389  5289]]\n",
      "[[13454   711]\n",
      " [ 1063  2228]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "print(confusion_matrix_train)\n",
    "print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Accuracy, True Positive Rate and True Negative Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Specificity:  0.9525898584049377\n",
      "Train Recall:  0.6888512633498307\n",
      "Train Precision:  0.771441073512252\n",
      "Train Accuracy:  0.9028725754971765\n"
     ]
    }
   ],
   "source": [
    "# Metrics on train data for ann_model 1\n",
    "#Accuracy\n",
    "accuracy_Train_M1 = (confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Train_M1 = confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Train_M1 = confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#precision\n",
    "precision_Train_M1 = confusion_matrix_train[1,1]/(confusion_matrix_train[0,1]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train Specificity: \",specificity_Train_M1)\n",
    "print(\"Train Recall: \",recall_Train_M1)\n",
    "print(\"Train Precision: \",precision_Train_M1)\n",
    "print(\"Train Accuracy: \",accuracy_Train_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Specificity:  0.9498058595128839\n",
      "Test Recall:  0.676997872986934\n",
      "Test Precision:  0.7580809799251446\n",
      "Test Accuracy:  0.8983730522456462\n"
     ]
    }
   ],
   "source": [
    "# Metrics on test data\n",
    "#Accuracy\n",
    "accuracy_Test_M1 = (confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Test_M1 = confusion_matrix_test[0,0]/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Test_M1 = confusion_matrix_test[1,1]/(confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#precision\n",
    "precision_Test_M1 = confusion_matrix_test[1,1]/(confusion_matrix_test[0,1]+confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test Specificity: \",specificity_Test_M1)\n",
    "print(\"Test Recall: \",recall_Test_M1)\n",
    "print(\"Test Precision: \",precision_Test_M1)\n",
    "print(\"Test Accuracy: \",accuracy_Test_M1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "print(model_history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('Accuracy Plot')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('Loss Function Plot')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Hidden Layers\n",
    "\n",
    "We have to be careful about overfitting!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32584 samples, validate on 8146 samples\n",
      "Epoch 1/10\n",
      "32584/32584 [==============================] - 4s 119us/step - loss: 0.4739 - acc: 0.8132 - val_loss: 0.4692 - val_acc: 0.8048\n",
      "Epoch 2/10\n",
      "32584/32584 [==============================] - 4s 112us/step - loss: 0.4411 - acc: 0.8132 - val_loss: 0.4332 - val_acc: 0.8048\n",
      "Epoch 3/10\n",
      "32584/32584 [==============================] - 4s 112us/step - loss: 0.3975 - acc: 0.8133 - val_loss: 0.3813 - val_acc: 0.8048\n",
      "Epoch 4/10\n",
      "32584/32584 [==============================] - 4s 113us/step - loss: 0.3519 - acc: 0.8365 - val_loss: 0.3374 - val_acc: 0.8479\n",
      "Epoch 5/10\n",
      "32584/32584 [==============================] - 4s 115us/step - loss: 0.3151 - acc: 0.8590 - val_loss: 0.3063 - val_acc: 0.8613\n",
      "Epoch 6/10\n",
      "32584/32584 [==============================] - 4s 115us/step - loss: 0.2903 - acc: 0.8707 - val_loss: 0.2858 - val_acc: 0.8715\n",
      "Epoch 7/10\n",
      "32584/32584 [==============================] - 4s 116us/step - loss: 0.2747 - acc: 0.8798 - val_loss: 0.2739 - val_acc: 0.8761\n",
      "Epoch 8/10\n",
      "32584/32584 [==============================] - 4s 115us/step - loss: 0.2656 - acc: 0.8854 - val_loss: 0.2683 - val_acc: 0.8833\n",
      "Epoch 9/10\n",
      "32584/32584 [==============================] - 4s 115us/step - loss: 0.2599 - acc: 0.8885 - val_loss: 0.2636 - val_acc: 0.8863\n",
      "Epoch 10/10\n",
      "32584/32584 [==============================] - 4s 116us/step - loss: 0.2558 - acc: 0.8908 - val_loss: 0.2591 - val_acc: 0.8883\n",
      "Confusion matrices:\n",
      "---------------------\n",
      "Confusion matrix - Train:\n",
      "[[31610  1442]\n",
      " [ 2959  4719]]\n",
      "Confusion matrix - Test:\n",
      "[[13514   651]\n",
      " [ 1298  1993]]\n",
      "---------------------\n",
      "Evaluation metrics on train data for new model:\n",
      "------------------------------------\n",
      "Train Specificity:  0.9563717778046714\n",
      "Train Recall:  0.6146131805157593\n",
      "Train Precision:  0.7659470865119299\n",
      "Train Accuracy:  0.8919469678369752\n",
      "------------------------------------\n",
      "Evaluation metrics on train data for model 1:\n",
      "Train Specificity:  0.9525898584049377\n",
      "Train Recall:  0.6888512633498307\n",
      "Train Precision:  0.771441073512252\n",
      "Train Accuracy:  0.9028725754971765\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Evaluation metrics on test data for new model:\n",
      "------------------------------------\n",
      "Test Specificity:  0.954041651959054\n",
      "Test Recall:  0.6055910057733211\n",
      "Test Precision:  0.7537821482602118\n",
      "Test Accuracy:  0.8883478460128322\n",
      "------------------------------------\n",
      "Evaluation metrics on test data for model 1:\n",
      "Test Specificity:  0.9498058595128839\n",
      "Test Recall:  0.676997872986934\n",
      "Test Precision:  0.7580809799251446\n",
      "Test Accuracy:  0.8983730522456462\n",
      "------------------------------------\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ann_model_hiddenExp = Sequential()\n",
    "\n",
    "# Adding more hidden layers\n",
    "ann_model_hiddenExp.add(Dense(1000, input_dim=21, activation='sigmoid', kernel_initializer='normal'))\n",
    "ann_model_hiddenExp.add(Dense(500, activation='sigmoid', kernel_initializer='normal'))\n",
    "ann_model_hiddenExp.add(Dense(100, activation='sigmoid', kernel_initializer='normal'))\n",
    "ann_model_hiddenExp.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))\n",
    "\n",
    "ann_model_hiddenExp.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "ann_model_hiddenExp.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Predictions\n",
    "train_pred = ann_model_hiddenExp.predict_classes(X_train)\n",
    "test_pred = ann_model_hiddenExp.predict_classes(X_test)\n",
    "\n",
    "#Evaluation metrics\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "print(\"Confusion matrices:\")\n",
    "print(\"---------------------\")\n",
    "print(\"Confusion matrix - Train:\")\n",
    "print(confusion_matrix_train)\n",
    "print(\"Confusion matrix - Test:\")\n",
    "print(confusion_matrix_test)\n",
    "print(\"---------------------\")\n",
    "\n",
    "# Metrics on train data\n",
    "#Accuracy\n",
    "accuracy_Train_hiddenExp = (confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Train_hiddenExp = confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Train_hiddenExp = confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#precision\n",
    "precision_Train_hiddenExp = confusion_matrix_train[1,1]/(confusion_matrix_train[0,1]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Evaluation metrics on train data for new model:\")\n",
    "print(\"------------------------------------\")\n",
    "print(\"Train Specificity: \",specificity_Train_hiddenExp)\n",
    "print(\"Train Recall: \",recall_Train_hiddenExp)\n",
    "print(\"Train Precision: \",precision_Train_hiddenExp)\n",
    "print(\"Train Accuracy: \",accuracy_Train_hiddenExp)\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print(\"Evaluation metrics on train data for model 1:\")\n",
    "print(\"Train Specificity: \",specificity_Train_M1)\n",
    "print(\"Train Recall: \",recall_Train_M1)\n",
    "print(\"Train Precision: \",precision_Train_M1)\n",
    "print(\"Train Accuracy: \",accuracy_Train_M1)\n",
    "print(\"------------------------------------\")\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Metrics on test data\n",
    "#Accuracy\n",
    "accuracy_Test_hiddenExp = (confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Test_hiddenExp = confusion_matrix_test[0,0]/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Test_hiddenExp = confusion_matrix_test[1,1]/(confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#precision\n",
    "precision_Test_hiddenExp = confusion_matrix_test[1,1]/(confusion_matrix_test[0,1]+confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Evaluation metrics on test data for new model:\")\n",
    "print(\"------------------------------------\")\n",
    "print(\"Test Specificity: \",specificity_Test_hiddenExp)\n",
    "print(\"Test Recall: \",recall_Test_hiddenExp)\n",
    "print(\"Test Precision: \",precision_Test_hiddenExp)\n",
    "print(\"Test Accuracy: \",accuracy_Test_hiddenExp)\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print(\"Evaluation metrics on test data for model 1:\")\n",
    "print(\"Test Specificity: \",specificity_Test_M1)\n",
    "print(\"Test Recall: \",recall_Test_M1)\n",
    "print(\"Test Precision: \",precision_Test_M1)\n",
    "print(\"Test Accuracy: \",accuracy_Test_M1)\n",
    "print(\"------------------------------------\")\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Experiment with learning rates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reference Material \n",
    "\n",
    "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "\n",
    "https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
